{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар по метрикам качества бинарной классификации\n",
    "\n",
    "## Теоретическая часть\n",
    "\n",
    "__Вспомнить из лекции:__\n",
    "* Как вычисляются следующие метрики качества: точность, полнота, F-мера, LogLoss, AUC-ROC, AUC-RPC?\n",
    "\n",
    "Большинство алгоритмов классификации работают следующим образом: они предсказывают для объекта $x$ вещественное число $b(x)$, а затем сравнивают его с порогом: если $b(x) < T$, то предсказывается класс -1, иначе предсказывается класс +1. Это можно записать в терминах функции sign (знак):\n",
    "$$a(x) = sign(b(x)-T)$$\n",
    "\n",
    "Соответственно, метрики качества бинарной классификации можно разделить на две группы: те, которые оценивают бинарные предсказания $a(x)$ (класс -1 и +1), и те, которые оценивают вещественные предсказания $b(x)$. Некоторые метрики последней группы варьируют порог, и оценивают качество бинарных предсказаний при различных порогах. Это полезно, чтобы \"отделить\" качество работы алгоритма от качества выбора конкретного порога.\n",
    "\n",
    "#### Вопрос: какие из рассмотренных на лекции метрик относятся к каждой группе?\n",
    "\n",
    "__Решение:__\n",
    "Оценивают бинарные предсказания: точность, полнота, F-мера\n",
    "\n",
    "Оценивают вещественные предсказания: LogLoss, AUC-ROC, AUC-RPC\n",
    "\n",
    "#### Задача 1\n",
    "Вычислите accuracy, точность, полноту и  F-меру для следующих векторов предсказаний и правильных ответов:\n",
    "\n",
    "|                               |    |    |    |    |    |    |    |\n",
    "|-------------------------------|----|----|----|----|----|----|----|\n",
    "| Правильный ответ (из данных) | +1 | -1 | +1 | +1 | -1 | +1 | -1 |\n",
    "| Предсказание                  | -1 | +1 | +1 | +1 | -1 | -1 | -1 |\n",
    "\n",
    "__Решение.__\n",
    "\n",
    "Accuracy - доля правильных ответов, то есть пар +1,+1 и -1,-1: 4/7\n",
    "\n",
    "Для вычисления precision, recall, F-меры построим матрицу ошибок:\n",
    "\n",
    "|                 | Правильный ответ +1 | Правильный ответ -1 |\n",
    "|-----------------|---------------------|---------------------|\n",
    "| Предсказание +1 | TP=2                   | FP=1                   |\n",
    "| Предсказание -1 | FN=2                   | TN=2                   |\n",
    "\n",
    "Точность (precision) - выделяем все объекты, на которых алгоритм предсказал класс +1 (TP+FP), и смотрим, какова доля объектов действительно класса +1 (TP). Ответ: TP / (TP+FP) = 2/3\n",
    "\n",
    "Полнота (recall) - выделяем все объекты класса +1 (TP+FN) и смотрим, какую долю алгоритм \"нашел\" (TP). Ответ: TP / (TP+FN) = 2/4 = 0.5\n",
    "\n",
    "F-мера - среднее гармоническое точности и полноты, вычисляем по формуле: 2 / (1/(2/3) + 1/0.5) = 4/7. F-мера будет большой, только если обе величины (и точность, и полнота) достаточно велики. В нашем примере низкая полнота, поэтому F-мера достаточно маленькая.\n",
    "\n",
    "#### Задача 2\n",
    "Рассмотрим алгоритм вида $a(x) = sign(b(x)-T)$. Пусть для любого объекта $x$ выполнено $-10 < b(x) < 10$. Какова будет точность и полнота алгоритма, если рассмотреть $T=-15$? $T=15$? \n",
    "\n",
    "__Решение.__\n",
    "Если установить значение порога $T=-15$, алгоритм $a(x)$ будет константным и для любого входного объекта будет возвращать класс $+1$ (так как для любого $x$ будет выполнено $b(x)-(-15) > 0$). Тогда FN=TN=0 (мы никогда не предсказываем класс -1). TP будет равно числу объектов класса +1 в выборке, FP - числу объектов класса -1. Тогда точность будет равна доле объектов класса +1 в выборке, а полнота единице (алгоритм \"нашел\" все объекты класса +1).\n",
    "\n",
    "Аналогично, если рассмотреть $T=15$, алгоритм $a(x)$ константный и всегда возвращает класс -1. В этом случае TP=FP=0 (мы никогда не предсказываем класс +1), TN равно числу объектов класса -1 в выборке, FN - числу объектов класса +1. В этом случае полнота равна 0, а точность равна 0/0, то есть не определена. Обычно используют \"презумцию\" хорошего алгоритма, и считают точность равной 1. Например, так можно делать, если нужно построить кривую точность-полнота.\n",
    "\n",
    "__Обратите внимание:__ при вычислении метрик мы не используем то, что отрицательный класс обозначен -1, а положительный - +1. Нам главное понимать, какой класс мы считаем положительным. Значения метрик не поменяются, если обозначить классы, например, 0 и 1.\n",
    "\n",
    "#### Задача 3\n",
    "\n",
    "Постройте ROC-кривую для следующих векторов предсказаний и правильных ответов:\n",
    "\n",
    "|                              |    |    |    |    |    |    |    |\n",
    "|------------------------------|----|----|----|----|----|----|----|\n",
    "| Правильный ответ (из данных) | -1 | +1 | +1 | -1 | +1 | -1 | -1 |\n",
    "| Предсказание $b(x)$       | 1  | 15 | -1 | 7  | 3  | -8 | -5 |\n",
    "\n",
    "__Решение.__\n",
    "\n",
    "ROC-кривая строится в осях FPR (абсцисса) и TPR (ордината), каждая из которых принимает значения от 0 до 1. TPR равна TP поделить на число объектов класса +1 в выборке. FPR равна FP поделить на число объектов класса -1 в выборке. \n",
    "\n",
    "Как уже было сказано выше, ROC-кривая оценивает качество вещественных предсказаний и пробует различные варианты порогов. Чтобы построить ROC-кривую, мы сначала сортируем объекты по возрастанию вещественных предсказаний $b(x)$, получим -8, -5, -1, 1, 3, 7, 15. Далее составляем вектор соответствующих этим предсказаниям правильных ответов, получим -1, -1, +1, -1, +1, -1, +1. В идеальной ситуации мы бы хотели, чтобы в этом векторе сначала шли все -1, а затем все +1. Это означало бы, что существует порог $T$, с которым у нас получится не ошибающийся итоговый алгоритм $a(x)$. Но на практике такого обычно не происходит, и метки классов оказываются перемешаны. По сути ROC-кривая показывает, насколько сильно они перемешаны.\n",
    "\n",
    "Далее мы представляем, что мы постепенно увеличиваем порог $T$, начиная с самого маленького. Поскольку всем объектам с величиной $b(x) < T$ предсказывается класс -1, а с величиной $b(x) > T$ - класс +1, то наш порог на каждом шаге будет \"перескакивать\" один объект, меняя на нем предсказание. В конце процесса у нас будет самое большое значение порога.\n",
    "\n",
    "Итак, рассмотрим сначала $T=-10$ (меньше любого $b(x)$). В этом случае мы на всех объекта предсказываем +1, TP равно числу объектов класса +1 в выборке, и TPR равно 1. Аналогично FP равно числу объектов класса -1 в выборке, и FPR равно 1. Значит, мы оказались в точке (1, 1) на графике ROC-кривой.\n",
    "\n",
    "Аналогично для самого большого порога $T=20$ (больше любого $b(x)$) предсказания на всех объектах равны -1, TP=FP=0, а значит, TPR=FPR=0, и мы оказываемся в точке (0, 0) на графике ROC-кривой.\n",
    "\n",
    "Когда мы увеличиваем порог от -10 до 20, мы строим кривую от точки (1, 1) к точке (0, 0). Чтобы нарисовать этот путь, надо сначала нарисовать сетку: поделить ось абсцисс на число объектов класса -1, а ось ординат - на число объектов класса +1. Затем надо по одному \"перескакивать\" через объекты, и если этот объект класса -1 - идти на один шаг влево, если класса +1 - на один шаг вниз. В идеальном случае мы прошли бы через точку (0, 1) - сначала много шагов влево, потом много шагом вниз. \n",
    "\n",
    "В нашем примере: вспоминаем соответствующую отсоритрованному вектору $b(x)$ последовательность меток -1, -1, +1, -1, +1, -1, +1. Делим ось абсцисс на 4 части (число -1), ось ординат - на 3 части (чило +1). На графике ROC начинаем из (1, 1), идем влево-влево-вниз-влево-вниз-влево-вниз (в соответствии с последовательностью меток). В итоге придем в (0, 0). После построения ROC-кривой можно посчитать площадь под ней - у нас получится 9 прямоугольников площадью 1/3 * 1/4 каждый, то есть 9/12=0.75.\n",
    "\n",
    "<div>\n",
    "<img src=\"roc.png\" width=\"200\"/>\n",
    "</div>\n",
    "\n",
    "__Обратите внимание:__ при построении ROC-кривой мы не используем значения вещественных предсказаний; вещественные предсказания используются только для того, чтобы отсортировать объекты. Поэтому совершенно необязательно, чтобы этими вещественными предсказаниями были вероятности класса +1. Это могут быть любые абстрактные величины, показывающие \"склонность\" объекта к классу +1.\n",
    "\n",
    "Если в предсказаниях $b(x)$ встречаются одинаковые значения с разными метками, получится шаг по диагонали.\n",
    "\n",
    "#### Задача 4\n",
    "\n",
    "Какое значение AUC-ROC будет у алгоритма $b(x)$, который на каждом объекте возвращает случайное вещественное число из отрезка [-2, 2] (равномерное распределение)? А у алгоритма, который для всех объектов класса -1 возвращает отрицательное число, а для всех объектов класса +1 - положительное число?\n",
    "\n",
    "__Решение.__\n",
    "\n",
    "\n",
    "Для первого алгоритма после сортировки объектов по возрастанию $b(x)$ получится случайный порядок меток -1 и +1. Значит, при построении ROC-кривой мы каждый раз будем случайно идти влево или вниз, и общая траектория движения будет около диагонали (0, 0) - (1, 1). Значит, значение AUC-ROC получится примерно 0.5.\n",
    "\n",
    "Для второго алгоритма после сортировки объектов по возрастанию $b(x)$ получится, что сначала идут -1, а потом +1. Значит, при построении ROC-кривой мы будем сначала идти влево до угла (0, 1), а зтем вниз до угла (0, 0). Значит, значение AUC-ROC будет равно единице.\n",
    "\n",
    "Мы рассмотрели два \"крайних\" случая: самый плохой и самый хороший алгоритм. Обычно значение AUC-ROC будет между 0.5 и 1.\n",
    "\n",
    "#### Задача 5\n",
    "\n",
    "Пусть для алгоритма $b(x)$ значение AUC-ROC равно 0.2. Каким будет AUC-ROC алгоритма $-b(x)$?\n",
    "\n",
    "__Решение.__\n",
    "\n",
    "Для алгоритма $-b(x)$ сортировка объектов будет в обратную сторону, чем для алгоритма $b(x)$, и порядок шагов тоже будет в обратную сторону. Это означает, что кривая \"повернется\" на 180 градусов, и AUC-ROC будет равен 1-0.2 = 0.8. \n",
    "\n",
    "Рассмотренные примеры показывают, что наихудшее значение AUC-ROC 0.5, а не 0 (так как из 0 всегда легко сделать 1).\n",
    "\n",
    "По схожим принципам (постепенное увеличение порога) можно построить кривую в осях полнота (абсцисса) - точность (ордината). Эти оси кажутся более привычными, поскольку на практике обычно используют именно эти две метрики. Однако кривая в этих осях получается менее наглядная. В частности, крайние точки такой кривой не (0, 0) и (1, 1), как у ROC-кривой, а (1, доля объектов класса +1) и (0, 1), причем последняя тока доопределена (см. задачу 2). И сама кривая в этом случае не будет монотонной.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn для вычисления метрик есть специальные функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, \\\n",
    "      precision_score, recall_score, f1_score, \\\n",
    "      roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем два бинарных вектора длины 100 (число объектов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "y_true = np.random.randint(2, size=n)\n",
    "y_pred = np.random.randint(2, size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим метрики качества бинарных предсказаний для случайных ответов (соответствует алгоритму, не выделяющему никаких закономерностей в данных):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5283018867924528, 0.4745762711864407, 0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true, y_pred), recall_score(y_true, y_pred), f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все метрики около 0.5 (примерная доля объектов положительного класса в выборке).\n",
    "\n",
    "Вычислим метрики для случая, когда все ответы правильные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true, y_true), recall_score(y_true, y_true), f1_score(y_true, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидается, все метрики равны 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем вектор случайных вещественных предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_pred = np.random.rand(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим roc_auc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5274906986357999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, b_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидается, значение ROC-AUC около 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
